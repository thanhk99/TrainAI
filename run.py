import json
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import TruncatedSVD
import re
import requests
import os
from typing import Dict, List
import warnings
warnings.filterwarnings('ignore')

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

class DataLoader:
    def __init__(self, data_path):
        self.data_path = data_path
        self.products = []
        
    def load_data(self):
        """Load dá»¯ liá»‡u tá»« file JSON"""
        try:
            with open(self.data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list):
                self.products = data
                print(f"âœ… ÄÃ£ load {len(self.products)} sáº£n pháº©m")
                return self.products, []
            else:
                raise ValueError("Cáº¥u trÃºc JSON khÃ´ng há»£p lá»‡")
                
        except Exception as e:
            print(f"âŒ Lá»—i load data: {e}")
            return [], []

import requests
import re
import json
import os
from typing import Dict

class GPTQueryAnalyzer:
    def __init__(self):
        # KHáº¨N Cáº¤P: XÃ“A API KEY KHá»I CODE!
        # Sá»­ dá»¥ng cÃ¡c cÃ¡ch báº£o máº­t bÃªn dÆ°á»›i
        self.api_key = self._get_api_key_safely()
        self.base_url = "https://api.openai.com/v1/chat/completions"
    
    def _get_api_key_safely(self):
        """Láº¥y API key an toÃ n - KHÃ”NG Ä‘á»ƒ trong code"""
        # Æ¯u tiÃªn 1: Environment variable
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            return api_key
            
        # Æ¯u tiÃªn 2: File .env
        try:
            from dotenv import load_dotenv
            load_dotenv()
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                return api_key
        except ImportError:
            pass
            
        # Æ¯u tiÃªn 3: File config.json
        try:
            with open('config.json', 'r') as f:
                config = json.load(f)
                api_key = config.get('OPENAI_API_KEY')
                if api_key:
                    return api_key
        except:
            pass
            
        # Æ¯u tiÃªn 4: Nháº­p tá»« ngÆ°á»i dÃ¹ng
        print("ğŸ”‘ KhÃ´ng tÃ¬m tháº¥y OpenAI API Key")
        api_key = input("Nháº­p API key cá»§a báº¡n (báº¯t Ä‘áº§u vá»›i sk-): ").strip()
        
        if api_key and api_key.startswith('sk-'):
            self._save_api_key(api_key)
            return api_key
        else:
            print("âš ï¸ API Key khÃ´ng há»£p lá»‡. Sá»­ dá»¥ng fallback mode.")
            return None
    
    def _save_api_key(self, api_key):
        """LÆ°u API key vÃ o file .env"""
        try:
            with open('.env', 'w') as f:
                f.write(f'OPENAI_API_KEY={api_key}\n')
            print("âœ… ÄÃ£ lÆ°u API key vÃ o file .env")
            
            # Táº¡o file .gitignore Ä‘á»ƒ trÃ¡nh commit nháº§m
            if not os.path.exists('.gitignore'):
                with open('.gitignore', 'w') as f:
                    f.write('.env\nconfig.json\n__pycache__/\n*.pyc\n')
        except Exception as e:
            print(f"âš ï¸ KhÃ´ng thá»ƒ lÆ°u API key: {e}")

    def analyze_query(self, user_query: str) -> Dict:
        """PhÃ¢n tÃ­ch query vá»›i GPT"""
        if not self.api_key:
            print("ğŸ”§ Sá»­ dá»¥ng fallback mode (khÃ´ng cÃ³ API key)")
            return self._fallback_analysis(user_query)
            
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        system_prompt = """Báº¡n lÃ  trá»£ lÃ½ AI cho siÃªu thá»‹. PhÃ¢n tÃ­ch query vÃ  tráº£ vá» JSON:
        {
            "original_query": "CÃ¢u há»i gá»‘c",
            "processed_query": "Tá»« khÃ³a tÃ¬m kiáº¿m",
            "intent": "search | recommendation | compare | budget",
            "category": "Danh má»¥c sáº£n pháº©m",
            "brand": "ThÆ°Æ¡ng hiá»‡u",
            "attributes": {
                "price_range": "low | medium | high | any",
                "purpose": "cooking | drinking | cleaning | personal_care | gift"
            }
        }"""
        
        payload = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_query}
            ],
            "temperature": 0.1,
            "max_tokens": 150
        }
        
        try:
            print("ğŸ”„ Äang phÃ¢n tÃ­ch vá»›i GPT...")
            response = requests.post(
                self.base_url, 
                headers=headers, 
                json=payload, 
                timeout=30  # TÄƒng timeout
            )
            
            # Xá»­ lÃ½ cÃ¡c mÃ£ lá»—i phá»• biáº¿n
            if response.status_code == 401:
                print("âŒ API Key khÃ´ng há»£p lá»‡ hoáº·c Ä‘Ã£ háº¿t háº¡n")
                return self._fallback_analysis(user_query)
            elif response.status_code == 429:
                print("âŒ QuÃ¡ giá»›i háº¡n rate limit - thá»­ láº¡i sau 60 giÃ¢y")
                return self._fallback_analysis(user_query)
            elif response.status_code == 403:
                print("âŒ TÃ i khoáº£n bá»‹ háº¡n cháº¿ hoáº·c háº¿t credit")
                return self._fallback_analysis(user_query)
            elif response.status_code == 500:
                print("âŒ Lá»—i server OpenAI - thá»­ láº¡i sau")
                return self._fallback_analysis(user_query)
            elif response.status_code != 200:
                print(f"âŒ Lá»—i API: {response.status_code} - {response.text}")
                return self._fallback_analysis(user_query)
                
            response.raise_for_status()
            
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            
            # Parse JSON tá»« response
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group())
                
                # TÃ­nh cost Æ°á»›c tÃ­nh
                usage = result.get('usage', {})
                total_tokens = usage.get('total_tokens', 0)
                cost = (total_tokens / 1000) * 0.002  # ~$0.002 per 1K tokens
                print(f"ğŸ’° Token usage: {total_tokens} (~${cost:.6f})")
                
                return self._validate_analysis(analysis, user_query)
            else:
                print("âŒ KhÃ´ng thá»ƒ parse JSON tá»« GPT response")
                return self._fallback_analysis(user_query)
                
        except requests.exceptions.Timeout:
            print("âŒ GPT request timeout sau 30 giÃ¢y")
            return self._fallback_analysis(user_query)
        except requests.exceptions.ConnectionError:
            print("âŒ Lá»—i káº¿t ná»‘i - kiá»ƒm tra internet")
            return self._fallback_analysis(user_query)
        except requests.exceptions.RequestException as e:
            print(f"âŒ Lá»—i request: {e}")
            return self._fallback_analysis(user_query)
        except Exception as e:
            print(f"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}")
            return self._fallback_analysis(user_query)
    
    def _validate_analysis(self, analysis: Dict, original_query: str) -> Dict:
        """Validate analysis result"""
        # Äáº£m báº£o processed_query khÃ´ng rá»—ng
        if not analysis.get('processed_query') or analysis['processed_query'].strip() == '':
            analysis['processed_query'] = self._simple_preprocess(original_query)
        
        # Äáº£m báº£o cÃ¡c trÆ°á»ng cáº§n thiáº¿t tá»“n táº¡i
        default_analysis = {
            "original_query": original_query,
            "processed_query": self._simple_preprocess(original_query),
            "intent": "search",
            "category": None,
            "brand": None,
            "attributes": {
                "price_range": "any",
                "purpose": "daily_use"
            }
        }
        
        # Merge vá»›i giÃ¡ trá»‹ máº·c Ä‘á»‹nh
        for key, default_value in default_analysis.items():
            if key not in analysis:
                analysis[key] = default_value
            elif isinstance(default_value, dict) and isinstance(analysis[key], dict):
                # Merge nested dictionaries
                for sub_key, sub_default in default_value.items():
                    if sub_key not in analysis[key]:
                        analysis[key][sub_key] = sub_default
        
        return analysis
    
    def _fallback_analysis(self, user_query: str) -> Dict:
        """Fallback analysis khi GPT khÃ´ng hoáº¡t Ä‘á»™ng"""
        query_lower = user_query.lower()
        
        # PhÃ¢n tÃ­ch intent Ä‘Æ¡n giáº£n
        intent = "search"
        if any(word in query_lower for word in ['gá»£i Ã½', 'nÃªn mua', 'khuyÃªn', 'recommend']):
            intent = "recommendation"
        elif any(word in query_lower for word in ['so sÃ¡nh', 'compare']):
            intent = "compare"
        elif any(word in query_lower for word in ['ráº»', 'giÃ¡', 'tiáº¿t kiá»‡m', 'budget']):
            intent = "budget"
        
        # PhÃ¢n tÃ­ch category Ä‘Æ¡n giáº£n
        category = None
        category_keywords = {
            "Thá»±c pháº©m": ['gáº¡o', 'cÆ¡m', 'mÃ¬', 'bÃºn', 'phá»Ÿ', 'thá»‹t', 'cÃ¡', 'rau', 'trÃ¡i cÃ¢y'],
            "Äá»“ uá»‘ng": ['nÆ°á»›c', 'bia', 'rÆ°á»£u', 'sá»¯a', 'cafe', 'trÃ ', 'nÆ°á»›c ngá»t'],
            "Gia dá»¥ng": ['bÃ n', 'gháº¿', 'tá»§', 'báº¿p', 'Ä‘Ã¨n', 'chÃ©n', 'dÄ©a', 'bÃ¡t'],
            "Vá»‡ sinh": ['giáº·t', 'táº©y', 'xÃ  phÃ²ng', 'dáº§u gá»™i', 'sá»¯a táº¯m', 'nÆ°á»›c rá»­a'],
            "Äiá»‡n tá»­": ['Ä‘iá»‡n thoáº¡i', 'tivi', 'tá»§ láº¡nh', 'mÃ¡y giáº·t']
        }
        
        for cat, keywords in category_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                category = cat
                break
        
        # PhÃ¢n tÃ­ch brand Ä‘Æ¡n giáº£n
        brand = None
        common_brands = ['vinamilk', 'cocacola', 'pepsi', 'tiger', 'heineken', 'panasonic']
        for brand_name in common_brands:
            if brand_name in query_lower:
                brand = brand_name
                break
        
        # PhÃ¢n tÃ­ch price range
        price_range = "any"
        if 'ráº»' in query_lower or 'giÃ¡ ráº»' in query_lower:
            price_range = "low"
        elif 'Ä‘áº¯t' in query_lower or 'cao cáº¥p' in query_lower:
            price_range = "high"
        
        return {
            "original_query": user_query,
            "processed_query": self._simple_preprocess(user_query),
            "intent": intent,
            "category": category,
            "brand": brand,
            "attributes": {
                "price_range": price_range,
                "purpose": "daily_use"
            }
        }
    
    def _simple_preprocess(self, query: str) -> str:
        """Tiá»n xá»­ lÃ½ query Ä‘Æ¡n giáº£n"""
        if not query:
            return ""
            
        stopwords = ['tÃ´i', 'muá»‘n', 'mua', 'cáº§n', 'tÃ¬m', 'cÃ³', 'nÃ o', 'áº¡', 'Æ¡i', 'cho']
        query = re.sub(r'[^\w\s]', ' ', query.lower())
        words = [word for word in query.split() if word not in stopwords and len(word) > 1]
        return ' '.join(words)
class SmartProductFilter:
    def __init__(self, products):
        self.products = products
        
    def apply_filters(self, products: List[Dict], analysis: Dict) -> List[Dict]:
        """Ãp dá»¥ng cÃ¡c bá»™ lá»c thÃ´ng minh"""
        filtered_products = products.copy()
        
        # Lá»c theo category
        if analysis["category"]:
            filtered_products = self._filter_by_category(filtered_products, analysis["category"])
        
        # Lá»c theo brand
        if analysis["brand"]:
            filtered_products = self._filter_by_brand(filtered_products, analysis["brand"])
        
        # Lá»c theo price range
        price_range = analysis["attributes"]["price_range"]
        if price_range != "any":
            filtered_products = self._filter_by_price(filtered_products, price_range)
        
        return filtered_products
    
    def _filter_by_category(self, products: List[Dict], category: str) -> List[Dict]:
        """Lá»c sáº£n pháº©m theo category"""
        category_lower = category.lower()
        filtered = []
        for product in products:
            product_category = product.get('category', '').lower()
            product_name = product.get('name', '').lower()
            
            if (category_lower in product_category or 
                category_lower in product_name):
                filtered.append(product)
        return filtered
    
    def _filter_by_brand(self, products: List[Dict], brand: str) -> List[Dict]:
        """Lá»c sáº£n pháº©m theo brand"""
        brand_lower = brand.lower()
        filtered = []
        for product in products:
            product_name = product.get('name', '').lower()
            product_desc = product.get('description', '').lower()
            
            if brand_lower in product_name or brand_lower in product_desc:
                filtered.append(product)
        return filtered
    
    def _filter_by_price(self, products: List[Dict], price_range: str) -> List[Dict]:
        """Lá»c sáº£n pháº©m theo khoáº£ng giÃ¡"""
        price_mapping = {
            "low": (0, 50000),
            "medium": (50000, 200000),
            "high": (200000, float('inf'))
        }
        
        if price_range in price_mapping:
            min_price, max_price = price_mapping[price_range]
            filtered = []
            for product in products:
                price = product.get('price', 0)
                if min_price <= price <= max_price:
                    filtered.append(product)
            return filtered
        return products

class EnhancedRecommender:
    def __init__(self, products):
        self.products = products
        self.tfidf_vectorizer = TfidfVectorizer(max_features=500)
        self.product_filter = SmartProductFilter(products)
        self.product_features = None
        self._prepare_product_data()
        
    def _prepare_product_data(self):
        """Chuáº©n bá»‹ dá»¯ liá»‡u sáº£n pháº©m"""
        self.product_texts = []
        for product in self.products:
            text_data = f"{product.get('name', '')} {product.get('category', '')} {product.get('description', '')} {product.get('content', '')}"
            self.product_texts.append(text_data)
    
    def extract_features(self):
        """TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng"""
        if not self.product_texts:
            self._prepare_product_data()
            
        try:
            tfidf_matrix = self.tfidf_vectorizer.fit_transform(self.product_texts)
            n_components = min(50, len(self.products)-1)
            
            if n_components > 0:
                self.svd = TruncatedSVD(n_components=n_components)
                self.product_features = self.svd.fit_transform(tfidf_matrix)
            else:
                self.product_features = tfidf_matrix.toarray()
                
        except Exception as e:
            print(f"âŒ Lá»—i extract features: {e}")
            # Fallback: random features
            self.product_features = np.random.rand(len(self.products), 50)
    
    def recommend(self, analysis_result: Dict, top_k: int = 10) -> List[Dict]:
        """Gá»£i Ã½ sáº£n pháº©m dá»±a trÃªn phÃ¢n tÃ­ch chi tiáº¿t"""
        if self.product_features is None:
            self.extract_features()
            
        # BÆ°á»›c 1: TÃ¬m kiáº¿m cÆ¡ báº£n dá»±a trÃªn processed_query
        query = analysis_result["processed_query"]
        if query and query.strip() != "":
            try:
                query_vec = self.tfidf_vectorizer.transform([query])
                
                if hasattr(self, 'svd'):
                    query_vec_reduced = self.svd.transform(query_vec)
                    similarities = cosine_similarity(query_vec_reduced, self.product_features)[0]
                else:
                    similarities = cosine_similarity(query_vec, self.product_features)[0]
                
                # Káº¿t há»£p sáº£n pháº©m vÃ  similarity scores
                scored_products = []
                for idx, similarity in enumerate(similarities):
                    if similarity > 0.01:  # NgÆ°á»¡ng tá»‘i thiá»ƒu
                        product = self.products[idx].copy()
                        product['similarity_score'] = float(similarity)
                        scored_products.append(product)
                
                # Sáº¯p xáº¿p theo similarity
                scored_products.sort(key=lambda x: x.get('similarity_score', 0), reverse=True)
                
            except Exception as e:
                print(f"âŒ Lá»—i tÃ¬m kiáº¿m: {e}")
                scored_products = self.products.copy()
        else:
            scored_products = self.products.copy()
        
        # BÆ°á»›c 2: Ãp dá»¥ng cÃ¡c bá»™ lá»c thÃ´ng minh
        filtered_products = self.product_filter.apply_filters(scored_products, analysis_result)
        
        # BÆ°á»›c 3: Æ¯u tiÃªn theo intent
        final_results = self._prioritize_by_intent(filtered_products, analysis_result["intent"])
        
        return final_results[:top_k]
    
    def _prioritize_by_intent(self, products: List[Dict], intent: str) -> List[Dict]:
        """Æ¯u tiÃªn sáº£n pháº©m dá»±a trÃªn Ã½ Ä‘á»‹nh"""
        if intent == "budget":
            # Æ¯u tiÃªn giÃ¡ ráº»
            return sorted(products, key=lambda x: x.get('price', float('inf')))
        elif intent == "compare":
            # Giá»¯ nguyÃªn thá»© tá»± similarity
            return products
        else:
            # Máº·c Ä‘á»‹nh: similarity score
            return sorted(products, key=lambda x: x.get('similarity_score', 0), reverse=True)

class SupermarketAI:
    def __init__(self, data_path):
        self.data_path = data_path
        self.data_loader = DataLoader(data_path)  # ÄÃƒ ÄÆ¯á»¢C Äá»ŠNH NGHÄ¨A
        self.gpt_analyzer = GPTQueryAnalyzer()
        self.recommender = None
        
    def initialize_system(self):
        """Khá»Ÿi táº¡o há»‡ thá»‘ng"""
        print("ğŸ”„ Äang khá»Ÿi táº¡o há»‡ thá»‘ng AI thÃ´ng minh...")
        
        # Load dá»¯ liá»‡u
        products, _ = self.data_loader.load_data()
        
        if not products:
            print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u sáº£n pháº©m")
            return False
            
        # Khá»Ÿi táº¡o recommender
        self.recommender = EnhancedRecommender(products)
        
        # Train model
        print("ğŸ”„ Training AI model...")
        self.recommender.extract_features()
        
        print("âœ… Há»‡ thá»‘ng AI thÃ´ng minh Ä‘Ã£ sáºµn sÃ ng!")
        return True
        
    def process_query(self, user_query: str, top_k: int = 5) -> Dict:
        """Xá»­ lÃ½ query ngÆ°á»i dÃ¹ng vá»›i GPT"""
        if not self.recommender:
            print("âŒ Há»‡ thá»‘ng chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o")
            return None
        
        # PhÃ¢n tÃ­ch query vá»›i GPT
        analysis = self.gpt_analyzer.analyze_query(user_query)
        
        print(f"\nğŸ” PHÃ‚N TÃCH GPT:")
        print(f"   Query gá»‘c: '{analysis['original_query']}'")
        print(f"   Query xá»­ lÃ½: '{analysis['processed_query']}'")
        print(f"   Ã Ä‘á»‹nh: {analysis['intent']}")
        print(f"   Danh má»¥c: {analysis['category']}")
        print(f"   ThÆ°Æ¡ng hiá»‡u: {analysis['brand']}")
        print(f"   Thuá»™c tÃ­nh: {analysis['attributes']}")
        
        # Láº¥y recommendations
        recommendations = self.recommender.recommend(analysis, top_k)
        
        return {
            'analysis': analysis,
            'recommendations': recommendations,
            'total_results': len(recommendations)
        }
    
    def display_recommendations(self, result):
        """Hiá»ƒn thá»‹ káº¿t quáº£ recommendations"""
        if not result or not result['recommendations']:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p")
            return
            
        analysis = result['analysis']
        
        print(f"\nğŸ¯ Káº¾T QUáº¢ CHO: '{analysis['original_query']}'")
        print(f"ğŸ“Š TÃ¬m tháº¥y {result['total_results']} sáº£n pháº©m phÃ¹ há»£p")
        print("=" * 80)
        
        for i, product in enumerate(result['recommendations'], 1):
            print(f"{i}. {product['name']}")
            print(f"   ğŸ“‚ Danh má»¥c: {product.get('category', 'N/A')}")
            print(f"   ğŸ’° GiÃ¡: {product.get('price', 'N/A'):,} VND")
            print(f"   ğŸ“¦ Tá»“n kho: {product.get('quantity', 'N/A')}")
            
            # Hiá»ƒn thá»‹ cÃ¡c scores náº¿u cÃ³
            if 'similarity_score' in product:
                print(f"   ğŸ” Äá»™ phÃ¹ há»£p: {product['similarity_score']:.3f}")
                
            print("-" * 50)

# HÃ m main Ä‘á»ƒ test
def main():
    data_path = "data.json"  # Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n Ä‘áº¿n file data cá»§a báº¡n
    
    # Khá»Ÿi táº¡o há»‡ thá»‘ng
    ai_system = SupermarketAI(data_path)
    
    if not ai_system.initialize_system():
        return
    
    # Test cÃ¡c query Ä‘a dáº¡ng
    test_queries = [
        "TÃ´i muá»‘n mua bÆ¡ láº¡t Anchor giÃ¡ ráº»",
    ]
    
    print("\n" + "="*80)
    print("ğŸ§ª TEST Há»† THá»NG AI THÃ”NG MINH Vá»šI GPT")
    print("="*80)
    
    for query in test_queries:
        print(f"\n{'='*50}")
        print(f"ğŸ§ª TEST: '{query}'")
        print('='*50)
        
        result = ai_system.process_query(query, top_k=3)
        ai_system.display_recommendations(result)

if __name__ == "__main__":
    main()